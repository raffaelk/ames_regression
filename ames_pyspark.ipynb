{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "careful-block",
   "metadata": {},
   "source": [
    "# House Price Prediction with PySpark\n",
    "\n",
    "Here, the hous price prediction task is solved by using the big data framework Apache Spark instead of scikit-learn. The house price data set is rather small, so using spark for this task is not efficient at all. But this model scales much better to bigger data sets, than a model using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "registered-diameter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.sql.functions import log, exp, lit\n",
    "from pyspark.ml.feature import Imputer, VectorAssembler, StandardScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "import pyspark.ml.tuning as tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "incorrect-european",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-theta",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "superior-introduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train and test data set\n",
    "data_loc = './data'\n",
    "\n",
    "train_data_base = spark.read.csv(os.path.join(data_loc,'train.csv'), inferSchema=True, header=True, nullValue='NA')\n",
    "test_data_base = spark.read.csv(os.path.join(data_loc,'test.csv'), inferSchema=True, header=True, nullValue='NA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-connection",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "middle-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine train and test set for the first preprocessing steps\n",
    "test_data_base = test_data_base.withColumn('SalesPrice', lit(0))\n",
    "test_data_base = test_data_base.withColumn('TainOrTest', lit('test'))\n",
    "\n",
    "train_data_base = train_data_base.withColumn('TrainOrTest', lit('train'))\n",
    "\n",
    "all_data_base = train_data_base.union(test_data_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "absolute-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace some categorical values with numerical ones\n",
    "\n",
    "# define replacements\n",
    "def binmap1(feature):\n",
    "    _map = {'Grvl':0, 'Pave':1}\n",
    "    return _map.get(feature, np.nan)\n",
    "\n",
    "def binmap2(feature):\n",
    "    _map= {'N':0, 'Y':1}\n",
    "    return _map.get(feature, np.nan)\n",
    "\n",
    "# create user defined functions\n",
    "udf_binmap1 = F.udf(binmap1, IntegerType())\n",
    "udf_binmap2 = F.udf(binmap2, IntegerType())\n",
    "\n",
    "# aplly the udf to the whole set\n",
    "all_data_base = all_data_base.withColumn('Street', udf_binmap1('Street'))\n",
    "all_data_base = all_data_base.withColumn('CentralAir', udf_binmap2('CentralAir'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "empty-giant",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map1(feature):\n",
    "    _map = {'Reg':0, 'IR1': 1, 'IR2':2, 'IR3':3}\n",
    "    return _map.get(feature, np.nan)\n",
    "    \n",
    "def map2(feature):\n",
    "    _map = {'Po':0, 'Fa':1, 'TA':2, 'Gd': 3, 'Ex':4}\n",
    "    return _map.get(feature, np.nan)\n",
    "    \n",
    "def map3(feature):\n",
    "    _map = {'Gtl':0, 'Mod':1, 'Sev':2}\n",
    "    return _map.get(feature, np.nan)\n",
    "    \n",
    "def map4(feature):\n",
    "    _map = {'NA':0, 'Po':1, 'Fa':2, 'TA':3, 'Gd': 4, 'Ex':5}\n",
    "    return _map.get(feature, np.nan)\n",
    "    \n",
    "def map5(feature):\n",
    "    _map = {'NA':0, 'No':1, 'Mn':2, 'Av':3, 'Gd': 4}\n",
    "    return _map.get(feature, np.nan)\n",
    "    \n",
    "def map6(feature):\n",
    "    _map = {'NA':0, 'Unf':1, 'LwQ':2, 'Rec':3, 'BLQ': 4, 'ALQ':5, 'GLQ':6}\n",
    "    return _map.get(feature, np.nan)\n",
    "\n",
    "def map7(feature):\n",
    "    _map = {'NA':0, 'Unf':1, 'RFn':2, 'Fin':3}\n",
    "    return _map.get(feature, np.nan)\n",
    "    \n",
    "def map8(feature):\n",
    "    _map = {'N':0, 'P':1, 'Y':2}\n",
    "    return _map.get(feature, np.nan)\n",
    "\n",
    "def map9(feature):\n",
    "    _map = {'NA':0, 'Fa':1, 'TA':2, 'Gd':3, 'Ex':4}\n",
    "    return _map.get(feature, np.nan)\n",
    "\n",
    "udf_map1 = F.udf(map1, IntegerType())\n",
    "udf_map2 = F.udf(map2, IntegerType())\n",
    "udf_map3 = F.udf(map3, IntegerType())\n",
    "udf_map4 = F.udf(map4, IntegerType())\n",
    "udf_map5 = F.udf(map5, IntegerType())\n",
    "udf_map6 = F.udf(map6, IntegerType())\n",
    "udf_map7 = F.udf(map7, IntegerType())\n",
    "udf_map8 = F.udf(map8, IntegerType())\n",
    "udf_map9 = F.udf(map9, IntegerType())\n",
    "\n",
    "\n",
    "all_data_base = all_data_base.withColumn('LotShape', udf_map1('LotShape'))\n",
    "all_data_base = all_data_base.withColumn('HeatingQC', udf_map2('HeatingQC'))\n",
    "all_data_base = all_data_base.withColumn('KitchenQual', udf_map2('KitchenQual'))\n",
    "all_data_base = all_data_base.withColumn('LandSlope', udf_map3('LandSlope'))\n",
    "all_data_base = all_data_base.withColumn('ExterQual', udf_map2('ExterQual'))\n",
    "all_data_base = all_data_base.withColumn('ExterCond', udf_map2('ExterCond'))\n",
    "all_data_base = all_data_base.withColumn('BsmtQual', udf_map4('BsmtQual'))\n",
    "all_data_base = all_data_base.withColumn('BsmtCond', udf_map4('BsmtCond'))\n",
    "all_data_base = all_data_base.withColumn('BsmtExposure', udf_map5('BsmtExposure'))\n",
    "all_data_base = all_data_base.withColumn('BsmtFinType1', udf_map6('BsmtFinType1'))\n",
    "all_data_base = all_data_base.withColumn('BsmtFinType2', udf_map6('BsmtFinType2'))\n",
    "all_data_base = all_data_base.withColumn('FireplaceQu', udf_map4('FireplaceQu'))\n",
    "all_data_base = all_data_base.withColumn('GarageFinish', udf_map7('GarageFinish'))\n",
    "all_data_base = all_data_base.withColumn('GarageQual', udf_map4('GarageQual'))\n",
    "all_data_base = all_data_base.withColumn('GarageCond', udf_map4('GarageCond'))\n",
    "all_data_base = all_data_base.withColumn('PavedDrive', udf_map8('PavedDrive'))\n",
    "all_data_base = all_data_base.withColumn('PoolQC', udf_map9('PoolQC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "focal-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all numerical columns\n",
    "num_features = [col_name for col_name, dtype in all_data_base.dtypes if dtype == \"int\"]\n",
    "\n",
    "# remove SalePrice, which is the target, and the Id column from the list of features\n",
    "num_features.remove(\"SalePrice\")\n",
    "num_features.remove(\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "pursuant-malpractice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast all numerical features to double (necessary for imputation)\n",
    "for feat in num_features:\n",
    "    all_data_base = all_data_base.withColumn(feat, all_data_base[feat].cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "restricted-radiation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split validation data\n",
    "train, val = all_data_base.where(all_data_base.TrainOrTest == 'train').randomSplit([.7, .3])\n",
    "\n",
    "# get the test set\n",
    "test = all_data_base.where(all_data_base.TrainOrTest == 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "responsible-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log-scale the SalePrice\n",
    "train = train.withColumn(\"SalePriceLog\", log(\"SalePrice\"))\n",
    "val = val.withColumn(\"SalePriceLog\", log(\"SalePrice\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-liver",
   "metadata": {},
   "source": [
    "## ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "japanese-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# names of the features afer imputation\n",
    "num_features_imp = [feat+\"_imp\" for feat in num_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "requested-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the ML pipeline\n",
    "\n",
    "# imputation of missing values\n",
    "imputer = Imputer(inputCols=num_features, outputCols=num_features_imp)\n",
    "\n",
    "# assembler to collect all the features\n",
    "vec_assembler = VectorAssembler(inputCols=num_features_imp, outputCol=\"features\")\n",
    "\n",
    "# scaling of the fetures\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\", withStd=True, withMean=True)\n",
    "\n",
    "# ridge regression\n",
    "regression = LinearRegression(featuresCol=\"features_scaled\", labelCol=\"SalePriceLog\", elasticNetParam=0)\n",
    "\n",
    "# pipeline, combining all the steps\n",
    "pipe = Pipeline(stages=[imputer, vec_assembler, scaler, regression])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "southwest-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a parameter gird for hyperparameter tuning\n",
    "grid = tune.ParamGridBuilder()\n",
    "grid = grid.addGrid(regression.regParam, [0.001, 0.01, 0.1, 1, 10, 50, 100, 500, 1000])\n",
    "grid = grid.addGrid(imputer.strategy, [\"mean\", \"median\"])\n",
    "grid = grid.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "norman-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the evaluation criteria\n",
    "evaluator = RegressionEvaluator(predictionCol=\"prediction\", labelCol=\"SalePriceLog\", metricName='rmse')\n",
    "\n",
    "# create the CrossValidator\n",
    "cv = tune.CrossValidator(estimator=pipe, estimatorParamMaps=grid, evaluator=evaluator)\n",
    "\n",
    "# fit cross validation models\n",
    "cv_models = cv.fit(train)\n",
    "\n",
    "# extract the best model\n",
    "bestPipeline = cv_models.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-better",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "worldwide-threshold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14618590836430886"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict and evaluate the validation set\n",
    "val_prediction = bestPipeline.transform(val)\n",
    "evaluator.evaluate(val_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hispanic-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test set\n",
    "test_prediction = bestPipeline.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "running-baking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the submission file \n",
    "submission = test_prediction.select(\"Id\", \"prediction\")\n",
    "submission = submission.withColumn(\"SalePrice\", exp(\"prediction\"))\n",
    "submission = submission.drop(\"prediction\")\n",
    "submission.write.csv(os.path.join(data_loc, \"submission_spark\"), header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-democrat",
   "metadata": {},
   "source": [
    "The submission scored 0.14394 on the kaggle public leader board."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
